{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook consists of build LSTM model on the data for COVID-19 Forecasting Week 4 .  \n",
    "#### The data consists of count of confirmed cases , number of fatalties recorded on dailly basis for 180 countries over a period of 72 days - 22nd Jan 2020 - 22nd Mar 2020. \n",
    "#### The ask is develop a predictive model which would forecast the number of covid cases and fatalities over the next 43 days for these 180 countries. For some countries, the data is also recorded for its indivual states, thus total number of regions - 313. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Bi-Directional LSTM model is trained to predict for next 43 steps for previous 29 steps. \n",
    "#### The timeseries are clustered into 10 groups using the K-Means algorithms  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import array\n",
    "from keras.preprocessing.text import one_hot\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Activation, Dropout, Dense\n",
    "from keras.layers import Flatten, LSTM\n",
    "from keras.layers import GlobalMaxPooling1D\n",
    "from keras.models import Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.layers import Input\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.layers import Bidirectional"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The below two funtions written to formulate the training data for confirmed cases and fatalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_confirmed_cases(data, n_input, n_out):\n",
    "    # flatten data\n",
    "    #data = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n",
    "    X, y = list(), list()\n",
    "    in_start = 0\n",
    "    # step over the entire history one time step at a time\n",
    "    for _ in range(len(data)):\n",
    "        #define the end of the input sequence\n",
    "        in_end = in_start + n_input\n",
    "        out_end = in_end + n_out\n",
    "        # ensure we have enough data for this instance\n",
    "        if out_end <= len(data):\n",
    "            x_input = data[in_start:in_end, :]\n",
    "            x_input = x_input.reshape((len(x_input), 11))\n",
    "            X.append(x_input)\n",
    "            y.append(data[in_end:out_end, 0])\n",
    "        # move along one time step\n",
    "        in_start += 1\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Fatalities\n",
    "def train_fatalities(data, n_input, n_out):\n",
    "    # flatten data\n",
    "    #data = train.reshape((train.shape[0]*train.shape[1], train.shape[2]))\n",
    "    X, y = list(), list()\n",
    "    in_start = 0\n",
    "    # step over the entire history one time step at a time\n",
    "    for _ in range(len(data)):\n",
    "        #define the end of the input sequence\n",
    "        in_end = in_start + n_input\n",
    "        out_end = in_end + n_out\n",
    "        # ensure we have enough data for this instance\n",
    "        if out_end <= len(data):\n",
    "            x_input = data[in_start:in_end, :]\n",
    "            x_input = x_input.reshape((len(x_input), 11))\n",
    "            X.append(x_input)\n",
    "            y.append(data[in_end:out_end, 0])\n",
    "        # move along one time step\n",
    "        in_start += 1\n",
    "    return np.array(X), np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The below fuuction is used to formulate the test data for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_cc(data, n_input, n_out):\n",
    "    Xtest = list()\n",
    "    in_start = 0\n",
    "    #for _ in range(len(data)):\n",
    "    in_end = in_start + n_input\n",
    "    #out_end = in_end + n_out\n",
    "    #if out_end <= len(data):\n",
    "    x_input = data[in_start:in_end, :]\n",
    "    x_input = x_input.reshape((len(x_input), 11))\n",
    "    Xtest.append(x_input)\n",
    "        #in_start += 1\n",
    "    return np.array(Xtest)\n",
    "def get_test_ft(data, n_input, n_out):\n",
    "    Xtest = list()\n",
    "    in_start = 0\n",
    "    #for _ in range(len(data)):\n",
    "    in_end = in_start + n_input\n",
    "    #out_end = in_end + n_out\n",
    "    #if out_end <= len(data):\n",
    "    x_input = data[in_start:in_end, :]\n",
    "    x_input = x_input.reshape((len(x_input), 11))\n",
    "    Xtest.append(x_input)\n",
    "        #in_start += 1\n",
    "    return np.array(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the Train Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The file 'Train_Data_Group.csv' is a modified file which has been created out of the first notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Train_Data_Group.csv',sep='|')\n",
    "country_state_province_list=list(set(list(df['Country_state_Province'])))\n",
    "#df[df['Country_state_Province']=='US-Minnesota']\n",
    "df2=pd.get_dummies(df, columns=['Group_Num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_list=['ConfirmedCases','Fatalities','Country_state_Province','Group_Num_0','Group_Num_1','Group_Num_2','Group_Num_3','Group_Num_4','Group_Num_5','Group_Num_6','Group_Num_7','Group_Num_8','Group_Num_9']\n",
    "df3=df2[cols_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=[]\n",
    "y_train=[]\n",
    "X_train_ft=[]\n",
    "y_train_ft=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for region in country_state_province_list:\n",
    "    dfregion=df3[df3['Country_state_Province']==region]\n",
    "    dfregion_vals_cc=dfregion.drop(['Country_state_Province','Fatalities'], axis=1).values\n",
    "    dfregion_vals_ft=dfregion.drop(['Country_state_Province','ConfirmedCases'], axis=1).values\n",
    "    x_train_row, y_train_row=train_confirmed_cases(dfregion_vals_cc, 29, 43)\n",
    "    x_train_row_ft, y_train_row_ft=train_fatalities(dfregion_vals_ft, 29, 43)\n",
    "    X_train.append(x_train_row)\n",
    "    y_train.append(y_train_row)\n",
    "    X_train_ft.append(x_train_row_ft)\n",
    "    y_train_ft.append(y_train_row_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(313, 8, 29, 11)\n",
      "(313, 8, 43)\n",
      "(313, 8, 29, 11)\n",
      "(313, 8, 43)\n"
     ]
    }
   ],
   "source": [
    "X_train_arr=np.array(X_train)\n",
    "y_train_arr=np.array(y_train)\n",
    "X_train_ft_arr=np.array(X_train_ft)\n",
    "y_train_ft_arr=np.array(y_train_ft)\n",
    "print(X_train_arr.shape)\n",
    "print(y_train_arr.shape)\n",
    "print(X_train_ft_arr.shape)\n",
    "print(y_train_ft_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2504, 29, 11)\n",
      "(2504, 43)\n",
      "(2504, 29, 11)\n",
      "(2504, 43)\n"
     ]
    }
   ],
   "source": [
    "X_train_arr=np.array(X_train).reshape(X_train_arr.shape[0]*X_train_arr.shape[1],29,11)\n",
    "y_train_arr=np.array(y_train).reshape(y_train_arr.shape[0]*y_train_arr.shape[1],43)\n",
    "X_train_ft_arr=np.array(X_train_ft).reshape(X_train_ft_arr.shape[0]*X_train_ft_arr.shape[1],29,11)\n",
    "y_train_ft_arr=np.array(y_train_ft).reshape(y_train_ft_arr.shape[0]*y_train_ft_arr.shape[1],43)\n",
    "print(X_train_arr.shape)\n",
    "print(y_train_arr.shape)\n",
    "print(X_train_ft_arr.shape)\n",
    "print(y_train_ft_arr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_arr=y_train_arr.reshape(2504,1,43)\n",
    "y_train_ft_arr=y_train_ft_arr.reshape(2504,1,43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[  94.,  105.,  122., ..., 1953., 2178., 2495.]],\n",
       "\n",
       "       [[ 105.,  122.,  147., ..., 2178., 2495., 2617.]],\n",
       "\n",
       "       [[ 122.,  147.,  159., ..., 2495., 2617., 3139.]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 576.,  576.,  576., ...,  579.,  579.,  579.]],\n",
       "\n",
       "       [[ 576.,  576.,  576., ...,  579.,  579.,  579.]],\n",
       "\n",
       "       [[ 576.,  576.,  576., ...,  579.,  579.,  579.]]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_arr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standardize dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scx=StandardScaler()\n",
    "scy=StandardScaler()\n",
    "sfx=StandardScaler()\n",
    "sfy=StandardScaler()\n",
    "X_train_arr_scaled=scx.fit_transform(X_train_arr.reshape(2504,29*11)).reshape(2504, 29, 11)\n",
    "y_train_arr_scaled=scy.fit_transform(y_train_arr.reshape(2504,43)).reshape(2504,1,43)\n",
    "X_train_ft_arr_scaled=sfx.fit_transform(X_train_ft_arr.reshape(2504,29*11)).reshape(2504, 29, 11)\n",
    "y_train_ft_arr_scaled=sfy.fit_transform(y_train_ft_arr.reshape(2504,43)).reshape(2504,1,43)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model to Train Confirmed Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import RepeatVector,TimeDistributed\n",
    "filepath=\"cc_model_weights_1_input_approach_best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2253 samples, validate on 251 samples\n",
      "Epoch 1/50\n",
      "2253/2253 [==============================] - 11s 5ms/step - loss: 0.8346 - val_loss: 0.0216\n",
      "Epoch 2/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.2670 - val_loss: 0.0133\n",
      "Epoch 3/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.2044 - val_loss: 0.0086\n",
      "Epoch 4/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1528 - val_loss: 0.0123\n",
      "Epoch 5/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1052 - val_loss: 0.0087\n",
      "Epoch 6/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0901 - val_loss: 0.0081\n",
      "Epoch 7/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0658 - val_loss: 0.0089\n",
      "Epoch 8/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0735 - val_loss: 0.0085\n",
      "Epoch 9/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0867 - val_loss: 0.0095\n",
      "Epoch 10/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0541 - val_loss: 0.0095\n",
      "Epoch 11/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0550 - val_loss: 0.0096\n",
      "Epoch 12/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0529 - val_loss: 0.0091\n",
      "Epoch 13/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0498 - val_loss: 0.0096\n",
      "Epoch 14/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0491 - val_loss: 0.0083\n",
      "Epoch 15/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0540 - val_loss: 0.0073\n",
      "Epoch 16/50\n",
      "2253/2253 [==============================] - 7s 3ms/step - loss: 0.0646 - val_loss: 0.0077\n",
      "Epoch 17/50\n",
      "2253/2253 [==============================] - 6s 3ms/step - loss: 0.0615 - val_loss: 0.0091\n",
      "Epoch 18/50\n",
      "2253/2253 [==============================] - 6s 3ms/step - loss: 0.0943 - val_loss: 0.0070\n",
      "Epoch 19/50\n",
      "2253/2253 [==============================] - 5s 2ms/step - loss: 0.2310 - val_loss: 0.0077\n",
      "Epoch 20/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.4358 - val_loss: 0.0101\n",
      "Epoch 21/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.8737 - val_loss: 0.0108\n",
      "Epoch 22/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1951 - val_loss: 0.0113\n",
      "Epoch 23/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1460 - val_loss: 0.0101\n",
      "Epoch 24/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1400 - val_loss: 0.0104\n",
      "Epoch 25/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.6561 - val_loss: 0.0100\n",
      "Epoch 26/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1604 - val_loss: 0.0079\n",
      "Epoch 27/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1041 - val_loss: 0.0081\n",
      "Epoch 28/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.1057 - val_loss: 0.0081\n",
      "Epoch 29/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0674 - val_loss: 0.0079\n",
      "Epoch 30/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0571 - val_loss: 0.0075\n",
      "Epoch 31/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0584 - val_loss: 0.0084\n",
      "Epoch 32/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0532 - val_loss: 0.0087\n",
      "Epoch 33/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0500 - val_loss: 0.0074\n",
      "Epoch 34/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0509 - val_loss: 0.0087\n",
      "Epoch 35/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0507 - val_loss: 0.0073\n",
      "Epoch 36/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0485 - val_loss: 0.0103\n",
      "Epoch 37/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0485 - val_loss: 0.0086\n",
      "Epoch 38/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0494 - val_loss: 0.0081\n",
      "Epoch 39/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0507 - val_loss: 0.0083\n",
      "Epoch 40/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0483 - val_loss: 0.0093\n",
      "Epoch 41/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0468 - val_loss: 0.0084\n",
      "Epoch 42/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0494 - val_loss: 0.0080\n",
      "Epoch 43/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0475 - val_loss: 0.0085\n",
      "Epoch 44/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0496 - val_loss: 0.0090\n",
      "Epoch 45/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0487 - val_loss: 0.0077\n",
      "Epoch 46/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0478 - val_loss: 0.0085\n",
      "Epoch 47/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0470 - val_loss: 0.0081\n",
      "Epoch 48/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0475 - val_loss: 0.0077\n",
      "Epoch 49/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0484 - val_loss: 0.0077\n",
      "Epoch 50/50\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.0463 - val_loss: 0.0079\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Bidirectional(LSTM(100, activation='relu'), input_shape=(29, 11)))\n",
    "model.add(RepeatVector(1))\n",
    "model.add(Bidirectional(LSTM(100, activation='relu', return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(43)))\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "history = model.fit(X_train_arr_scaled, y_train_arr_scaled, epochs=50, validation_split=0.1, verbose=1, batch_size=50,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model to Train Fatalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "filepath=\"ft_model_weights_1_input_approach_best.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, save_best_only=True, mode='auto')\n",
    "callbacks_list = [checkpoint]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2253 samples, validate on 251 samples\n",
      "Epoch 1/20\n",
      "2253/2253 [==============================] - 7s 3ms/step - loss: 1.4513 - val_loss: 0.0070\n",
      "Epoch 2/20\n",
      "2253/2253 [==============================] - 3s 2ms/step - loss: 3.4481 - val_loss: 0.0032\n",
      "Epoch 3/20\n",
      "2253/2253 [==============================] - 3s 2ms/step - loss: 1368.7576 - val_loss: 0.0065\n",
      "Epoch 4/20\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 46.9273 - val_loss: 0.0030\n",
      "Epoch 5/20\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 18.2414 - val_loss: 0.0017\n",
      "Epoch 6/20\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 35.6411 - val_loss: 0.0017\n",
      "Epoch 7/20\n",
      "2253/2253 [==============================] - 3s 2ms/step - loss: 6.8277 - val_loss: 0.0018\n",
      "Epoch 8/20\n",
      "2253/2253 [==============================] - 5s 2ms/step - loss: 1.2902 - val_loss: 0.0017\n",
      "Epoch 9/20\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 1.3597 - val_loss: 0.0017\n",
      "Epoch 10/20\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 1.0058 - val_loss: 0.0016\n",
      "Epoch 11/20\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.9958 - val_loss: 0.0017\n",
      "Epoch 12/20\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.9942 - val_loss: 0.0016\n",
      "Epoch 13/20\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.9990 - val_loss: 0.0017\n",
      "Epoch 14/20\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 1.0004 - val_loss: 0.0017\n",
      "Epoch 15/20\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 1.0021 - val_loss: 0.0015\n",
      "Epoch 16/20\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.9938 - val_loss: 0.0016\n",
      "Epoch 17/20\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 1.0482 - val_loss: 0.0016\n",
      "Epoch 18/20\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 0.9911 - val_loss: 0.0016\n",
      "Epoch 19/20\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 26.0419 - val_loss: 0.0034\n",
      "Epoch 20/20\n",
      "2253/2253 [==============================] - 4s 2ms/step - loss: 1.9045 - val_loss: 0.0024\n"
     ]
    }
   ],
   "source": [
    "model1 = Sequential()\n",
    "model1.add(Bidirectional(LSTM(100, activation='relu'), input_shape=(29, 11)))\n",
    "model1.add(RepeatVector(1))\n",
    "model1.add(Bidirectional(LSTM(100, activation='relu', return_sequences=True)))\n",
    "model1.add(TimeDistributed(Dense(43)))\n",
    "model1.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "history = model1.fit(X_train_ft_arr_scaled, y_train_ft_arr_scaled, epochs=20, validation_split=0.1, verbose=1, batch_size=50,callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formulate the data for prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_list=['ConfirmedCases','Fatalities','Country_state_Province','Group_Num_0','Group_Num_1','Group_Num_2','Group_Num_3','Group_Num_4','Group_Num_5','Group_Num_6','Group_Num_7','Group_Num_8','Group_Num_9']\n",
    "dftest_all_cols=df2[df2['Day']>50]\n",
    "dftest=dftest_all_cols[cols_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(313, 1, 29, 11)\n",
      "(313, 1, 29, 11)\n",
      "(313, 29, 11)\n"
     ]
    }
   ],
   "source": [
    "X_test_CC=[]\n",
    "X_test_FT=[]\n",
    "for region in country_state_province_list:\n",
    "    dfregion=dftest[dftest['Country_state_Province']==region]\n",
    "    dfregion_vals_cc=dfregion.drop(['Country_state_Province','Fatalities'], axis=1).values\n",
    "    dfregion_vals_ft=dfregion.drop(['Country_state_Province','ConfirmedCases'], axis=1).values\n",
    "    x_test_row_cc=get_test_cc(dfregion_vals_cc, 29, 43)\n",
    "    x_test_row_ft=get_test_ft(dfregion_vals_ft, 29, 43)\n",
    "    #x_train_row_ft, y_train_row_ft=to_supervised_fatalities(dfregi\n",
    "    X_test_CC.append(x_test_row_cc)\n",
    "    X_test_FT.append(x_test_row_ft)\n",
    "X_test_cc_arr=np.array(X_test_CC)\n",
    "X_test_ft_arr=np.array(X_test_FT)\n",
    "print(X_test_cc_arr.shape)\n",
    "print(X_test_ft_arr.shape)\n",
    "X_test_cc_arr=np.array(X_test_CC).reshape(X_test_cc_arr.shape[0]*X_test_cc_arr.shape[1],29,11)\n",
    "X_test_ft_arr=np.array(X_test_FT).reshape(X_test_ft_arr.shape[0]*X_test_ft_arr.shape[1],29,11)\n",
    "print(X_test_cc_arr.shape)\n",
    "X_test_cc_arr_scaled=scx.transform(X_test_cc_arr.reshape(313,29*11)).reshape(313, 29, 11)\n",
    "X_test_ff_arr_scaled=sfx.transform(X_test_ft_arr.reshape(313,29*11)).reshape(313, 29, 11)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predict the Data Using the two trained models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cc_pred=model.predict(X_test_cc_arr_scaled)\n",
    "y_ft_pred=model1.predict(X_test_ff_arr_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_cc_pred_inv_out=scy.inverse_transform(y_cc_pred.reshape(313,43))\n",
    "y_ft_pred_inv_out=sfy.inverse_transform(y_ft_pred.reshape(313,43))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "dte_list=[]\n",
    "import datetime\n",
    "\n",
    "start = datetime.datetime.strptime(\"2020-04-02\", \"%Y-%m-%d\")\n",
    "end = datetime.datetime.strptime(\"2020-05-15\", \"%Y-%m-%d\")\n",
    "date_generated = [start + datetime.timedelta(days=x) for x in range(0, (end-start).days)]\n",
    "\n",
    "for date in date_generated:\n",
    "    dte_list.append(date.strftime(\"%Y-%m-%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_list=[]\n",
    "for i in range(1,44):\n",
    "    day_list.append('Day_' +str(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Predict_Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Day_1</td>\n",
       "      <td>2020-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Day_2</td>\n",
       "      <td>2020-04-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Day_3</td>\n",
       "      <td>2020-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Day_4</td>\n",
       "      <td>2020-04-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Day_5</td>\n",
       "      <td>2020-04-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Day Predict_Date\n",
       "0  Day_1   2020-04-02\n",
       "1  Day_2   2020-04-03\n",
       "2  Day_3   2020-04-04\n",
       "3  Day_4   2020-04-05\n",
       "4  Day_5   2020-04-06"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dresult_base=pd.DataFrame(data=day_list, index=range(len(day_list)), columns=['Day'])\n",
    "dresult_base['Predict_Date']=dte_list\n",
    "dresult_base.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "dresult_out=pd.DataFrame(columns=['Day','Predict_Date','Region','Predicted_Confirmed_Cases','Predicted_Fatalities'])\n",
    "for j in range(len(country_state_province_list)):\n",
    "    dresult_region=dresult_base\n",
    "    dresult_region['Region']=country_state_province_list[j]\n",
    "    dresult_region['Predicted_Confirmed_Cases']=y_cc_pred_inv_out[j]\n",
    "    dresult_region['Predicted_Fatalities']=y_ft_pred_inv_out[j]\n",
    "    dresult_out=dresult_out.append(dresult_region)\n",
    "    dresult_out.index=range(len(dresult_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "dresult_out.to_csv('Coronavirus_Forecast_LSTM_Model_Week_4.csv',sep='|')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging the Result with the Test file for submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ForecastId</th>\n",
       "      <th>Province_State</th>\n",
       "      <th>Country_Region</th>\n",
       "      <th>Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-04-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-04-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-04-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-04-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>2020-04-06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ForecastId Province_State Country_Region        Date\n",
       "0           1            NaN    Afghanistan  2020-04-02\n",
       "1           2            NaN    Afghanistan  2020-04-03\n",
       "2           3            NaN    Afghanistan  2020-04-04\n",
       "3           4            NaN    Afghanistan  2020-04-05\n",
       "4           5            NaN    Afghanistan  2020-04-06"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtest_input=pd.read_csv('test.csv')\n",
    "dtest_input.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest_input['Province_State'].fillna('NA', inplace=True)\n",
    "dtest_input['Country_Region_Province']=dtest_input['Country_Region']+'-'+dtest_input['Province_State']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>Predict_Date</th>\n",
       "      <th>Region</th>\n",
       "      <th>Predicted_Confirmed_Cases</th>\n",
       "      <th>Predicted_Fatalities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Day_1</td>\n",
       "      <td>2020-04-02</td>\n",
       "      <td>China-Hebei</td>\n",
       "      <td>436.487518</td>\n",
       "      <td>10.074240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Day_2</td>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>China-Hebei</td>\n",
       "      <td>357.098358</td>\n",
       "      <td>16.962048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Day_3</td>\n",
       "      <td>2020-04-04</td>\n",
       "      <td>China-Hebei</td>\n",
       "      <td>345.330658</td>\n",
       "      <td>18.204575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Day_4</td>\n",
       "      <td>2020-04-05</td>\n",
       "      <td>China-Hebei</td>\n",
       "      <td>626.100159</td>\n",
       "      <td>15.599738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Day_5</td>\n",
       "      <td>2020-04-06</td>\n",
       "      <td>China-Hebei</td>\n",
       "      <td>396.978729</td>\n",
       "      <td>14.349257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Day Predict_Date       Region  Predicted_Confirmed_Cases  \\\n",
       "0  Day_1   2020-04-02  China-Hebei                 436.487518   \n",
       "1  Day_2   2020-04-03  China-Hebei                 357.098358   \n",
       "2  Day_3   2020-04-04  China-Hebei                 345.330658   \n",
       "3  Day_4   2020-04-05  China-Hebei                 626.100159   \n",
       "4  Day_5   2020-04-06  China-Hebei                 396.978729   \n",
       "\n",
       "   Predicted_Fatalities  \n",
       "0             10.074240  \n",
       "1             16.962048  \n",
       "2             18.204575  \n",
       "3             15.599738  \n",
       "4             14.349257  "
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dresult_out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_result=pd.merge(dresult_out,dtest_input, how='inner',left_on=['Region','Predict_Date'], right_on=['Country_Region_Province','Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\ravi_\\appdata\\local\\programs\\python\\python35\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "kaggle_out_df=d_result[['ForecastId','Predicted_Confirmed_Cases','Predicted_Fatalities']]\n",
    "kaggle_out_df.sort_values(by=['ForecastId'],inplace=True)\n",
    "kaggle_out_df.to_csv('submission.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dumping the objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Scaler_Fatalities_Y.pkl']"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(scx,'Scaler_Confirmed_Cases_X.pkl')\n",
    "joblib.dump(scy,'Scaler_Confirmed_Cases_Y.pkl')\n",
    "joblib.dump(sfx,'Scaler_Fatalities_X.pkl')\n",
    "joblib.dump(sfy,'Scaler_Fatalities_Y.pkl')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
